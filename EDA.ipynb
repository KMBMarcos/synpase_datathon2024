{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "4f4d3143-8a86-411d-84e7-4cb928207ef9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Generated requirements.txt successfully in the data directory!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('src')\n",
    "sys.path.append('models')\n",
    "sys.path.append('data')\n",
    "#from librerias import *\n",
    "from utils import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#install_requirements()\n",
    "generate_requirements_txt(\"requirements.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2bcf575a-8d4f-4a23-a272-e8c93961609c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 33623 entries, 0 to 33622\n",
      "Data columns (total 10 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   churned                    33623 non-null  bool   \n",
      " 1   dias_atraso                33623 non-null  float64\n",
      " 2   limite_credito             33623 non-null  float64\n",
      " 3   tiene_cuenta               33582 non-null  float64\n",
      " 4   año_activacion             33623 non-null  int32  \n",
      " 5   mes_activacion             33623 non-null  int32  \n",
      " 6   dia_activacion             33623 non-null  int32  \n",
      " 7   edad                       33546 non-null  float64\n",
      " 8   id_tipo_ocupacion_encoded  33623 non-null  int32  \n",
      " 9   nombre_ocupacion_encoded   33623 non-null  int32  \n",
      "dtypes: bool(1), float64(4), int32(5)\n",
      "memory usage: 1.7 MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 33546 entries, 0 to 33622\n",
      "Data columns (total 10 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   churned                    33546 non-null  bool   \n",
      " 1   dias_atraso                33546 non-null  float64\n",
      " 2   limite_credito             33546 non-null  float64\n",
      " 3   tiene_cuenta               33546 non-null  float64\n",
      " 4   año_activacion             33546 non-null  int32  \n",
      " 5   mes_activacion             33546 non-null  int32  \n",
      " 6   dia_activacion             33546 non-null  int32  \n",
      " 7   edad                       33546 non-null  float64\n",
      " 8   id_tipo_ocupacion_encoded  33546 non-null  int32  \n",
      " 9   nombre_ocupacion_encoded   33546 non-null  int32  \n",
      "dtypes: bool(1), float64(4), int32(5)\n",
      "memory usage: 2.0 MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1500 entries, 0 to 1499\n",
      "Data columns (total 10 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   id                         1500 non-null   object \n",
      " 1   dias_atraso                1500 non-null   float64\n",
      " 2   limite_credito             1500 non-null   float64\n",
      " 3   tiene_cuenta               1500 non-null   float64\n",
      " 4   año_activacion             1500 non-null   int32  \n",
      " 5   mes_activacion             1500 non-null   int32  \n",
      " 6   dia_activacion             1500 non-null   int32  \n",
      " 7   edad                       1500 non-null   float64\n",
      " 8   id_tipo_ocupacion_encoded  1500 non-null   int32  \n",
      " 9   nombre_ocupacion_encoded   1500 non-null   int32  \n",
      "dtypes: float64(4), int32(5), object(1)\n",
      "memory usage: 88.0+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "\n",
    "# Cargar los datos\n",
    "df_target_participantes = pd.read_csv(\"./data/df_entrenamiento/df_target_participantes.csv\")\n",
    "df_cobros_participantes = pd.read_csv(\"./data/df_entrenamiento/df_cobros_participantes.csv\")\n",
    "df_Clientes = pd.merge(df_target_participantes, df_cobros_participantes, on='id')\n",
    "\n",
    "df_consumos_participantes = pd.read_csv(\"./data/df_entrenamiento/consumos_participantes.csv\")\n",
    "df_loans_participantes = pd.read_csv(\"./data/df_entrenamiento/df_loans_participantes.csv\")\n",
    "df_quejas_participantes = pd.read_csv(\"./data/df_entrenamiento/df_quejas_participantes.csv\")\n",
    "\n",
    "# Crear nuevas columnas de año, mes y día de activación y calcular edad\n",
    "current_year = datetime.datetime.now().year\n",
    "df_Clientes['año_activacion'] = pd.to_datetime(df_Clientes['fecha_activacion']).dt.year\n",
    "df_Clientes['mes_activacion'] = pd.to_datetime(df_Clientes['fecha_activacion']).dt.month\n",
    "df_Clientes['dia_activacion'] = pd.to_datetime(df_Clientes['fecha_activacion']).dt.day\n",
    "df_Clientes['edad'] = current_year - pd.to_datetime(df_Clientes['fecha_nacimiento']).dt.year\n",
    "df_Clientes['sector'] = df_Clientes['sector'].str.replace('ENSANCHE', '', regex=False).str.strip()\n",
    "\n",
    "\n",
    "# Convertir 'tiene_cuenta' de tipo string a booleano\n",
    "df_Clientes['tiene_cuenta'] = df_Clientes['tiene_cuenta'].map({True: 1, False: 0})\n",
    "df_Clientes.head()\n",
    "# Codificación de variables categóricas con LabelEncoder\n",
    "leOcupaciontipo = LabelEncoder()\n",
    "leOcupacionnombre = LabelEncoder()\n",
    "leSector = LabelEncoder()\n",
    "leCiudad = LabelEncoder()\n",
    "\n",
    "df_Clientes['id_tipo_ocupacion_encoded'] = leOcupaciontipo.fit_transform(df_Clientes['id_tipo_ocupacion'].astype(str))\n",
    "df_Clientes['nombre_ocupacion_encoded'] = leOcupacionnombre.fit_transform(df_Clientes['nombre_ocupacion'].astype(str))\n",
    "#df_Clientes['sector_encoded'] = leSector.fit_transform(df_Clientes['sector'].astype(str))\n",
    "#df_Clientes['ciudad_encoded'] = leCiudad.fit_transform(df_Clientes['ciudad'].astype(str))\n",
    "\n",
    "# Eliminar columnas originales de ocupación y otras innecesarias\n",
    "df_transform = df_Clientes.drop(columns=['id', 'fecha_activacion', 'fecha_nacimiento', 'id_tipo_ocupacion', 'nombre_ocupacion', 'sector', 'ciudad','Fecha de Cancelacion_mes','TC_garantizada','id_ocupacion','probabilidad_default_TC'])\n",
    "print(df_transform.info())\n",
    "df_transform=df_transform.dropna()\n",
    "print(df_transform.info())\n",
    "# Separar características (X) y target (y)\n",
    "X = df_transform.drop(columns=['churned'])\n",
    "y = df_transform['churned']\n",
    "\n",
    "# Dividir el conjunto de datos en entrenamiento (80%) y prueba (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Escalamiento de las características\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "df_Cliente_validacion.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6c583cca-b532-4981-b8f9-09b346c98bbc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1500 entries, 0 to 1499\n",
      "Data columns (total 13 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id                       1500 non-null   object \n",
      " 1   dias_atraso              1500 non-null   float64\n",
      " 2   limite_credito           1500 non-null   float64\n",
      " 3   fecha_activacion         1500 non-null   object \n",
      " 4   probabilidad_default_TC  967 non-null    float64\n",
      " 5   tiene_cuenta             1499 non-null   object \n",
      " 6   sector                   1383 non-null   object \n",
      " 7   ciudad                   1445 non-null   object \n",
      " 8   TC_garantizada           1139 non-null   object \n",
      " 9   id_ocupacion             478 non-null    float64\n",
      " 10  id_tipo_ocupacion        478 non-null    float64\n",
      " 11  nombre_ocupacion         478 non-null    object \n",
      " 12  fecha_nacimiento         1497 non-null   object \n",
      "dtypes: float64(5), object(8)\n",
      "memory usage: 152.5+ KB\n"
     ]
    }
   ],
   "source": [
    "pd.merge(df_target_validacion_solo_id, df_cobros_validacion, on='id').info()\n",
    "## TC_garantizada es true o false\n",
    "##Probabilidad default es un numero normalizado de 0 a 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d13b2fad-1960-483e-9216-5ba3998c2755",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 33623 entries, 0 to 33622\n",
      "Data columns (total 21 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   churned                    33623 non-null  bool   \n",
      " 1   id                         33623 non-null  object \n",
      " 2   Fecha de Cancelacion_mes   2828 non-null   object \n",
      " 3   dias_atraso                33623 non-null  float64\n",
      " 4   limite_credito             33623 non-null  float64\n",
      " 5   fecha_activacion           33623 non-null  object \n",
      " 6   probabilidad_default_TC    21688 non-null  float64\n",
      " 7   tiene_cuenta               33582 non-null  object \n",
      " 8   sector                     31026 non-null  object \n",
      " 9   ciudad                     32543 non-null  object \n",
      " 10  TC_garantizada             25597 non-null  object \n",
      " 11  id_ocupacion               11022 non-null  float64\n",
      " 12  id_tipo_ocupacion          11022 non-null  float64\n",
      " 13  nombre_ocupacion           11022 non-null  object \n",
      " 14  fecha_nacimiento           33546 non-null  object \n",
      " 15  año_activacion             33623 non-null  int64  \n",
      " 16  mes_activacion             33623 non-null  int64  \n",
      " 17  dia_activacion             33623 non-null  int64  \n",
      " 18  edad                       33546 non-null  float64\n",
      " 19  id_tipo_ocupacion_encoded  33623 non-null  int64  \n",
      " 20  nombre_ocupacion_encoded   33623 non-null  int32  \n",
      "dtypes: bool(1), float64(6), int32(1), int64(4), object(9)\n",
      "memory usage: 5.3+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "leOcupaciontipo = LabelEncoder()\n",
    "leOcupacionnombre = LabelEncoder()\n",
    "# Cargar los datos\n",
    "df_target_participantes = pd.read_csv(\"./data/df_entrenamiento/df_target_participantes.csv\")\n",
    "df_cobros_participantes = pd.read_csv(\"./data/df_entrenamiento/df_cobros_participantes.csv\")\n",
    "df_Clientes = pd.merge(df_target_participantes, df_cobros_participantes, on='id')\n",
    "\n",
    "df_consumos_participantes = pd.read_csv(\"./data/df_entrenamiento/consumos_participantes.csv\")\n",
    "df_loans_participantes = pd.read_csv(\"./data/df_entrenamiento/df_loans_participantes.csv\")\n",
    "df_quejas_participantes = pd.read_csv(\"./data/df_entrenamiento/df_quejas_participantes.csv\")\n",
    "\n",
    "# Assuming df_Clientes is your DataFrame\n",
    "\n",
    "# Get the current year\n",
    "current_year = datetime.datetime.now().year\n",
    "\n",
    "# Create new columns for year, month, and day of activation (as numbers)\n",
    "df_Clientes['año_activacion'] = pd.to_datetime(df_Clientes['fecha_activacion']).dt.year\n",
    "df_Clientes['mes_activacion'] = pd.to_datetime(df_Clientes['fecha_activacion']).dt.month\n",
    "df_Clientes['dia_activacion'] = pd.to_datetime(df_Clientes['fecha_activacion']).dt.day\n",
    "\n",
    "# Calculate age using the current year\n",
    "df_Clientes['edad'] = current_year - pd.to_datetime(df_Clientes['fecha_nacimiento']).dt.year\n",
    "\n",
    "df_Clientes['id_tipo_ocupacion_encoded'] = leleOcupaciontipo.fit_transform(df_Clientes['id_tipo_ocupacion'])\n",
    "df_Clientes['nombre_ocupacion_encoded'] = leleOcupacionnombre.fit_transform(df_Clientes['nombre_ocupacion'])\n",
    "df_transform = df_Clientes.drop(['id_tipo_ocupacion','nombre_ocupacion', ])\n",
    "df_Churned = df_Clientes[df_Clientes['churned']== 1]\n",
    "df_NOt_Churned = df_Clientes[df_Clientes['churned']== False]\n",
    "df_Clientes.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac90dcc-82ae-4a5d-b815-9e6577e09005",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 33623 entries, 0 to 33622\n",
      "Data columns (total 10 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   churned                    33623 non-null  bool   \n",
      " 1   dias_atraso                33623 non-null  float64\n",
      " 2   limite_credito             33623 non-null  float64\n",
      " 3   tiene_cuenta               33582 non-null  float64\n",
      " 4   año_activacion             33623 non-null  int32  \n",
      " 5   mes_activacion             33623 non-null  int32  \n",
      " 6   dia_activacion             33623 non-null  int32  \n",
      " 7   edad                       33546 non-null  float64\n",
      " 8   id_tipo_ocupacion_encoded  33623 non-null  int32  \n",
      " 9   nombre_ocupacion_encoded   33623 non-null  int32  \n",
      "dtypes: bool(1), float64(4), int32(5)\n",
      "memory usage: 1.7 MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 33546 entries, 0 to 33622\n",
      "Data columns (total 10 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   churned                    33546 non-null  bool   \n",
      " 1   dias_atraso                33546 non-null  float64\n",
      " 2   limite_credito             33546 non-null  float64\n",
      " 3   tiene_cuenta               33546 non-null  float64\n",
      " 4   año_activacion             33546 non-null  int32  \n",
      " 5   mes_activacion             33546 non-null  int32  \n",
      " 6   dia_activacion             33546 non-null  int32  \n",
      " 7   edad                       33546 non-null  float64\n",
      " 8   id_tipo_ocupacion_encoded  33546 non-null  int32  \n",
      " 9   nombre_ocupacion_encoded   33546 non-null  int32  \n",
      "dtypes: bool(1), float64(4), int32(5)\n",
      "memory usage: 2.0 MB\n",
      "None\n",
      "\n",
      "Porcentaje de Varianza: 99%\n",
      "Cantidad de características seleccionadas: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 20/29 [03:11<00:56,  6.31s/it]"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "\n",
    "# Cargar los datos\n",
    "df_target_participantes = pd.read_csv(\"./data/df_entrenamiento/df_target_participantes.csv\")\n",
    "df_cobros_participantes = pd.read_csv(\"./data/df_entrenamiento/df_cobros_participantes.csv\")\n",
    "df_Clientes = pd.merge(df_target_participantes, df_cobros_participantes, on='id')\n",
    "\n",
    "df_consumos_participantes = pd.read_csv(\"./data/df_entrenamiento/consumos_participantes.csv\")\n",
    "df_loans_participantes = pd.read_csv(\"./data/df_entrenamiento/df_loans_participantes.csv\")\n",
    "df_quejas_participantes = pd.read_csv(\"./data/df_entrenamiento/df_quejas_participantes.csv\")\n",
    "\n",
    "# Crear nuevas columnas de año, mes y día de activación y calcular edad\n",
    "current_year = datetime.datetime.now().year\n",
    "df_Clientes['año_activacion'] = pd.to_datetime(df_Clientes['fecha_activacion']).dt.year\n",
    "df_Clientes['mes_activacion'] = pd.to_datetime(df_Clientes['fecha_activacion']).dt.month\n",
    "df_Clientes['dia_activacion'] = pd.to_datetime(df_Clientes['fecha_activacion']).dt.day\n",
    "df_Clientes['edad'] = current_year - pd.to_datetime(df_Clientes['fecha_nacimiento']).dt.year\n",
    "df_Clientes['sector'] = df_Clientes['sector'].str.replace('ENSANCHE', '', regex=False).str.strip()\n",
    "\n",
    "\n",
    "# Convertir 'tiene_cuenta' de tipo string a booleano\n",
    "df_Clientes['tiene_cuenta'] = df_Clientes['tiene_cuenta'].map({True: 1, False: 0})\n",
    "df_Clientes.head()\n",
    "# Codificación de variables categóricas con LabelEncoder\n",
    "leOcupaciontipo = LabelEncoder()\n",
    "leOcupacionnombre = LabelEncoder()\n",
    "leSector = LabelEncoder()\n",
    "leCiudad = LabelEncoder()\n",
    "\n",
    "df_Clientes['id_tipo_ocupacion_encoded'] = leOcupaciontipo.fit_transform(df_Clientes['id_tipo_ocupacion'].astype(str))\n",
    "df_Clientes['nombre_ocupacion_encoded'] = leOcupacionnombre.fit_transform(df_Clientes['nombre_ocupacion'].astype(str))\n",
    "#df_Clientes['sector_encoded'] = leSector.fit_transform(df_Clientes['sector'].astype(str))\n",
    "#df_Clientes['ciudad_encoded'] = leCiudad.fit_transform(df_Clientes['ciudad'].astype(str))\n",
    "\n",
    "# Eliminar columnas originales de ocupación y otras innecesarias\n",
    "df_transform = df_Clientes.drop(columns=['id', 'fecha_activacion', 'fecha_nacimiento', 'id_tipo_ocupacion', 'nombre_ocupacion', 'sector', 'ciudad','Fecha de Cancelacion_mes','TC_garantizada','id_ocupacion','probabilidad_default_TC'])\n",
    "print(df_transform.info())\n",
    "df_transform.to_csv(\"Tabla_utilizada.csv\", index=False)\n",
    "df_transform=df_transform.dropna()\n",
    "print(df_transform.info())\n",
    "# Separar características (X) y target (y)\n",
    "X = df_transform.drop(columns=['churned'])\n",
    "y = df_transform['churned']\n",
    "\n",
    "# Dividir el conjunto de datos en entrenamiento (80%) y prueba (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Escalamiento de las características\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Definir porcentajes de varianza para el PCA\n",
    "variance_percentages = [99, 90, 80, 70, 60, 50]\n",
    "\n",
    "# Realizar PCA para cada porcentaje de varianza y obtener los componentes principales\n",
    "best_models = {}\n",
    "for variance_percentage in variance_percentages:\n",
    "    pca = PCA(n_components=variance_percentage / 100)\n",
    "    X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "    X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "    # Imprimir la cantidad de características después del PCA\n",
    "    print(f\"\\nPorcentaje de Varianza: {variance_percentage}%\")\n",
    "    print(f\"Cantidad de características seleccionadas: {pca.n_components_}\")\n",
    "\n",
    "    # Usar Lazy Predict para encontrar los mejores modelos\n",
    "    clf = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric=None)\n",
    "    models_summary, _ = clf.fit(X_train_pca, X_test_pca, y_train, y_test)\n",
    "\n",
    "    # Obtener los nombres de los 5 mejores modelos y guardarlos en un diccionario\n",
    "    best_models[variance_percentage] = models_summary.head(5)\n",
    "\n",
    "# Mostrar los mejores modelos para cada porcentaje de varianza\n",
    "for variance_percentage, models_summary in best_models.items():\n",
    "    print(f\"\\nPorcentaje de Varianza: {variance_percentage}%\")\n",
    "    print(models_summary)\n",
    "    print(\"--------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ca00415-1101-49bc-817d-5dc0af870382",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_target_validacion_solo_id \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./data/df_validacion/df_target_validacion_solo_id.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m df_cobros_validacion \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./data/df_validacion/df_cobros_validacion.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m df_Cliente_validacion \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(df_target_validacion_solo_id, df_cobros_validacion, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df_target_validacion_solo_id = pd.read_csv(\"./data/df_validacion/df_target_validacion_solo_id.csv\")\n",
    "df_cobros_validacion = pd.read_csv(\"./data/df_validacion/df_cobros_validacion.csv\")\n",
    "df_Cliente_validacion = pd.merge(df_target_validacion_solo_id, df_cobros_validacion, on='id')\n",
    "\n",
    "# Crear nuevas columnas de año, mes y día de activación y calcular edad\n",
    "current_year = datetime.datetime.now().year\n",
    "df_Cliente_validacion['año_activacion'] = pd.to_datetime(df_Cliente_validacion['fecha_activacion']).dt.year\n",
    "df_Cliente_validacion['mes_activacion'] = pd.to_datetime(df_Cliente_validacion['fecha_activacion']).dt.month\n",
    "df_Cliente_validacion['dia_activacion'] = pd.to_datetime(df_Cliente_validacion['fecha_activacion']).dt.day\n",
    "df_Cliente_validacion['edad'] = current_year - pd.to_datetime(df_Cliente_validacion['fecha_nacimiento']).dt.year\n",
    "edad_promedio = df_Cliente_validacion['edad'].mean()\n",
    "df_Cliente_validacion['edad'].fillna(edad_promedio, inplace=True)\n",
    "df_Cliente_validacion['sector'] = df_Cliente_validacion['sector'].str.replace('ENSANCHE', '', regex=False).str.strip()\n",
    "\n",
    "# Codificar variables categóricas\n",
    "df_Cliente_validacion['tiene_cuenta'] = df_Cliente_validacion['tiene_cuenta'].map({True: 1, False: 0})\n",
    "moda = df_Cliente_validacion['tiene_cuenta'].mode()[0]\n",
    "df_Cliente_validacion['tiene_cuenta'].fillna(moda, inplace=True)\n",
    "\n",
    "df_Cliente_validacion['id_tipo_ocupacion_encoded'] = leOcupaciontipo.transform(df_Cliente_validacion['id_tipo_ocupacion'].astype(str))\n",
    "df_Cliente_validacion['nombre_ocupacion_encoded'] = leOcupacionnombre.transform(df_Cliente_validacion['nombre_ocupacion'].astype(str))\n",
    "#df_Cliente_validacion['sector_encoded'] = leSector.transform(df_Cliente_validacion['sector'].astype(str))\n",
    "#df_Cliente_validacion['ciudad_encoded'] = leCiudad.transform(df_Cliente_validacion['ciudad'].astype(str))\n",
    "\n",
    "\n",
    "# Eliminar columnas innecesarias\n",
    "df_Cliente_validacion = df_Cliente_validacion.drop(columns=[ 'fecha_activacion', 'fecha_nacimiento', 'id_tipo_ocupacion', 'nombre_ocupacion', 'sector', 'ciudad','TC_garantizada','sector','id_ocupacion','probabilidad_default_TC'])\n",
    "print(df_Cliente_validacion.info())\n",
    "df_Cliente_validacion= df_Cliente_validacion.dropna()\n",
    "print(df_Cliente_validacion.info())\n",
    "# Escalar características\n",
    "X_validacion = df_Cliente_validacion.drop(columns=['id'])\n",
    "X_validacion_scaled = scaler.transform(X_validacion)\n",
    "\n",
    "# Aplicar PCA\n",
    "pca = PCA(n_components=0.9)  # Por ejemplo, seleccionar el 90% de varianza\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_validacion_pca = pca.transform(X_validacion_scaled)\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Seleccionar el modelo (por ejemplo, LGBMClassifier)\n",
    "model = LGBMClassifier()\n",
    "\n",
    "# Entrenar el modelo con los datos de entrenamiento\n",
    "model.fit(X_train_pca, y_train)\n",
    "\n",
    "# Realizar predicciones con el conjunto de datos de validación\n",
    "y_pred_proba = model.predict_proba(X_validacion_pca)[:, 1]\n",
    "\n",
    "# Crear archivo de predicciones\n",
    "predicciones = pd.DataFrame({'id': df_Cliente_validacion['id'], 'churned': y_pred_proba})\n",
    "predicciones.to_csv(\"prediction_Synapse.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6002c16a-5ebd-465f-919f-368b2cd45d95",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_Clientes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdf_Clientes\u001b[49m\u001b[38;5;241m.\u001b[39minfo()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_Clientes' is not defined"
     ]
    }
   ],
   "source": [
    "df_Clientes.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e825d24c-cd92-41e5-8118-b46f111feac7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b00c062-4168-4404-8ad0-7702835740f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imblearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder, StandardScaler\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecomposition\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PCA\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimblearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlazypredict\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mSupervised\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LazyClassifier\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Cargar los datos\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'imblearn'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "\n",
    "# Cargar los datos\n",
    "df_target_participantes = pd.read_csv(\"./data/df_entrenamiento/df_target_participantes.csv\")\n",
    "df_cobros_participantes = pd.read_csv(\"./data/df_entrenamiento/df_cobros_participantes.csv\")\n",
    "df_Clientes = pd.merge(df_target_participantes, df_cobros_participantes, on='id')\n",
    "\n",
    "df_consumos_participantes = pd.read_csv(\"./data/df_entrenamiento/consumos_participantes.csv\")\n",
    "df_loans_participantes = pd.read_csv(\"./data/df_entrenamiento/df_loans_participantes.csv\")\n",
    "df_quejas_participantes = pd.read_csv(\"./data/df_entrenamiento/df_quejas_participantes.csv\")\n",
    "\n",
    "# Crear nuevas columnas de año, mes y día de activación y calcular edad\n",
    "current_year = datetime.datetime.now().year\n",
    "df_Clientes['año_activacion'] = pd.to_datetime(df_Clientes['fecha_activacion']).dt.year\n",
    "df_Clientes['mes_activacion'] = pd.to_datetime(df_Clientes['fecha_activacion']).dt.month\n",
    "df_Clientes['dia_activacion'] = pd.to_datetime(df_Clientes['fecha_activacion']).dt.day\n",
    "df_Clientes['edad'] = current_year - pd.to_datetime(df_Clientes['fecha_nacimiento']).dt.year\n",
    "df_Clientes['sector'] = df_Clientes['sector'].str.replace('ENSANCHE', '', regex=False).str.strip()\n",
    "\n",
    "# Convertir 'tiene_cuenta' de tipo string a booleano\n",
    "df_Clientes['tiene_cuenta'] = df_Clientes['tiene_cuenta'].map({True: 1, False: 0})\n",
    "df_Clientes.head()\n",
    "\n",
    "# Codificación de variables categóricas con LabelEncoder\n",
    "leOcupaciontipo = LabelEncoder()\n",
    "leOcupacionnombre = LabelEncoder()\n",
    "leSector = LabelEncoder()\n",
    "leCiudad = LabelEncoder()\n",
    "\n",
    "df_Clientes['id_tipo_ocupacion_encoded'] = leOcupaciontipo.fit_transform(df_Clientes['id_tipo_ocupacion'].astype(str))\n",
    "df_Clientes['nombre_ocupacion_encoded'] = leOcupacionnombre.fit_transform(df_Clientes['nombre_ocupacion'].astype(str))\n",
    "\n",
    "# Eliminar columnas originales de ocupación y otras innecesarias\n",
    "df_transform = df_Clientes.drop(columns=['id', 'fecha_activacion', 'fecha_nacimiento', 'id_tipo_ocupacion', 'nombre_ocupacion', 'sector', 'ciudad', 'Fecha de Cancelacion_mes', 'TC_garantizada', 'id_ocupacion', 'probabilidad_default_TC'])\n",
    "df_transform = df_transform.dropna()\n",
    "\n",
    "# Separar características (X) y target (y)\n",
    "X = df_transform.drop(columns=['churned'])\n",
    "y = df_transform['churned']\n",
    "\n",
    "# Aplicar SMOTE para balancear las clases\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Dividir el conjunto de datos en entrenamiento (80%) y prueba (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Escalamiento de las características\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Definir porcentajes de varianza para el PCA\n",
    "variance_percentages = [99, 90, 80, 70, 60, 50]\n",
    "\n",
    "# Realizar PCA para cada porcentaje de varianza y obtener los componentes principales\n",
    "best_models = {}\n",
    "for variance_percentage in variance_percentages:\n",
    "    pca = PCA(n_components=variance_percentage / 100)\n",
    "    X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "    X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "    # Imprimir la cantidad de características después del PCA\n",
    "    print(f\"\\nPorcentaje de Varianza: {variance_percentage}%\")\n",
    "    print(f\"Cantidad de características seleccionadas: {pca.n_components_}\")\n",
    "\n",
    "    # Usar Lazy Predict para encontrar los mejores modelos\n",
    "    clf = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric=None)\n",
    "    models_summary, _ = clf.fit(X_train_pca, X_test_pca, y_train, y_test)\n",
    "\n",
    "    # Obtener los nombres de los 5 mejores modelos y guardarlos en un diccionario\n",
    "    best_models[variance_percentage] = models_summary.head(5)\n",
    "\n",
    "# Mostrar los mejores modelos para cada porcentaje de varianza\n",
    "for variance_percentage, models_summary in best_models.items():\n",
    "    print(f\"\\nPorcentaje de Varianza: {variance_percentage}%\")\n",
    "    print(models_summary)\n",
    "    print(\"--------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c6b5b3-d556-46a6-82b1-c5e5a292738f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, ExtraTreesClassifier\n",
    "\n",
    "# Supongo que X_train_scaled, X_test_scaled, y_train, y_test ya están definidos\n",
    "# según el código anterior\n",
    "\n",
    "# Definir los clasificadores y sus parámetros para GridSearch\n",
    "classifiers_params = {\n",
    "    'XGBClassifier': {\n",
    "        'classifier': XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
    "        'params': {\n",
    "            'learning_rate': [0.01, 0.1, 0.2],\n",
    "            'max_depth': [3, 5, 7],\n",
    "            'n_estimators': [50, 100, 200]\n",
    "        }\n",
    "    },\n",
    "    'LGBMClassifier': {\n",
    "        'classifier': LGBMClassifier(),\n",
    "        'params': {\n",
    "            'learning_rate': [0.01, 0.1, 0.2],\n",
    "            'max_depth': [3, 5, 7],\n",
    "            'n_estimators': [50, 100, 200]\n",
    "        }\n",
    "\n",
    "    }\n",
    "}\n",
    "\n",
    "# Guardar los resultados\n",
    "results = []\n",
    "\n",
    "# Optimizar los clasificadores con GridSearch y calcular métricas\n",
    "for clf_name, clf_params in classifiers_params.items():\n",
    "    grid_search = GridSearchCV(clf_params['classifier'], clf_params['params'], cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "    grid_search.fit(X_train_pca, y_train)\n",
    "\n",
    "    best_clf = grid_search.best_estimator_\n",
    "\n",
    "    # Predicciones en el conjunto de prueba\n",
    "    y_pred = best_clf.predict(X_validacion_pca)\n",
    "\n",
    "    # Matriz de confusión\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(f'Matriz de Confusión - {clf_name}:')\n",
    "    print(cm)\n",
    "\n",
    "    # Reporte de clasificación\n",
    "    cr = classification_report(y_test, y_pred)\n",
    "    print(f'Reporte de Clasificación - {clf_name}:')\n",
    "    print(cr)\n",
    "\n",
    "    # Guardar los resultados para la tabla\n",
    "    results.append({\n",
    "        'Model': clf_name,\n",
    "        'Best Params': grid_search.best_params_,\n",
    "        'Confusion Matrix': cm,\n",
    "        'Classification Report': cr\n",
    "    })\n",
    "\n",
    "    # Importancia de las características (si está disponible)\n",
    "    if hasattr(best_clf, 'feature_importances_'):\n",
    "        importances = best_clf.feature_importances_\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.barplot(x=importances, y=pca.get_feature_names_out())\n",
    "        plt.title(f'Importancia de las características - {clf_name}')\n",
    "        plt.show()\n",
    "\n",
    "    # Calcular curva ROC y AUC solo si el clasificador tiene predict_proba\n",
    "    if hasattr(best_clf, 'predict_proba'):\n",
    "        y_prob = best_clf.predict_proba(X_validacion_pca)[:, 1]\n",
    "        auc = roc_auc_score(y_test, y_prob)\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(fpr, tpr, label=f'AUC = {auc:.2f}')\n",
    "        plt.plot([0, 1], [0, 1], 'k--')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title(f'Curva ROC - {clf_name}')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.show()\n",
    "\n",
    "# Crear tabla de resultados\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results[['Model', 'Best Params', 'Classification Report']]\n",
    "\n",
    "# Mostrar los resultados en una tabla\n",
    "df_results[['Model', 'Best Params']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
